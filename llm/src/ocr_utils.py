"""
ocr_utils.py
-------------
P√§ivitetty versio: k√§ytt√§√§ Unstructured.io- ja PyMuPDF-pohjaista dokumenttien
k√§sittely√§, korvaa vanhan Docling + EasyOCR -pipeline.
S√§ilytt√§√§ dokumentin rakenteen (otsikot, kappaleet, luettelot)
ja toimii t√§ysin offline. Yhteensopiva indexing.py:n kanssa.
"""
import os

import json
from pathlib import Path
from datetime import datetime
from unstructured.partition.pdf import partition_pdf
from unstructured.partition.docx import partition_docx
from unstructured.partition.text import partition_text
from unstructured.chunking.title import chunk_by_title
from unstructured.documents.elements import NarrativeText, Title, ListItem
from .config import PROCESSED_DIR, LOG_DIR
import fitz  # PyMuPDF



# ---------------------------------------------------------------------------
# üîß Lokitustuki
# ---------------------------------------------------------------------------
def log_ocr_warning(file_path, message):
    """Kirjaa OCR- ja k√§sittelyvaroitukset lokitiedostoon."""
    log_file = LOG_DIR / "ocr_failures.log"
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(log_file, "a", encoding="utf-8") as f:
        f.write(f"[{timestamp}] {file_path}: {message}\n")
    print(f"‚ö†Ô∏è {message}")


# ---------------------------------------------------------------------------
# üìò Dokumenttien k√§sittely
# ---------------------------------------------------------------------------
def extract_text_unstructured(file_path: str):
    """Lukee PDF-, DOCX- tai TXT-tiedoston ja palauttaa sen tekstin."""
    path = Path(file_path)
    suffix = path.suffix.lower()

    try:
        if suffix == ".pdf":
            elements = partition_pdf(
            file_path,
            strategy="hi_res",
            infer_table_structure=True,
            languages=["fi", "en"],  # ‚úÖ OCR suomi + englanti
        )

        elif suffix == ".docx":
            elements = partition_docx(file_path)
        elif suffix == ".txt":
            elements = partition_text(file_path)
        else:
            log_ocr_warning(file_path, f"‚ùå Tuntematon tiedostomuoto: {suffix}")
            return ""

        # Poistetaan ei-tekstielementit (kuvat, taulukot, metatiedot)
        text_elements = [
            el for el in elements
            if isinstance(el, (NarrativeText, Title, ListItem))
        ]

        full_text = "\n\n".join([el.text for el in text_elements if el.text.strip()])
        return full_text.strip()

    except Exception as e:
        log_ocr_warning(file_path, f"Unstructured-k√§sittely ep√§onnistui: {e}")
        return ""


# ---------------------------------------------------------------------------
# üß† OCR-varamenetelm√§
# ---------------------------------------------------------------------------
def run_paddleocr_fallback(file_path: str):
    """K√§ytt√§√§ PaddleOCR:ia, jos PDF:ss√§ ei ole tekstitasoja."""
    try:
        from paddleocr import PaddleOCR
        import torch

        print(f"üîç K√§ynnistet√§√§n PaddleOCR-varamenetelm√§: {file_path}")
        use_gpu = torch.cuda.is_available()  # ‚úÖ tarkistaa, onko GPU k√§yt√∂ss√§
        ocr = PaddleOCR(lang="fi", use_angle_cls=True, use_gpu=use_gpu)  # ‚úÖ k√§ytt√§√§ GPU:ta, jos saatavilla
        doc = fitz.open(file_path)

        text_output = ""
        for i, page in enumerate(doc):
            pix = page.get_pixmap(dpi=200)
            result = ocr.ocr(pix.tobytes(), cls=False)
            page_text = " ".join(
                [line[1][0] for line in result[0]]
            ) if result and result[0] else ""
            print(f"üìÑ OCR-sivu {i+1}: {len(page_text)} merkki√§")
            text_output += page_text + "\n"

        return text_output.strip()

    except Exception as e:
        log_ocr_warning(file_path, f"PaddleOCR ep√§onnistui: {e}")
        return ""


# ---------------------------------------------------------------------------
# ‚öôÔ∏è Prosessointip√§√§funktio
# ---------------------------------------------------------------------------
def process_with_unstructured(file_path: str):
    """
    K√§sittelee dokumentin rakenteisesti Unstructuredin avulla.
    Tallentaa JSON-tiedoston ja palauttaa tekstikappaleet.
    """
    raw_path = Path(file_path)
    output_file = PROCESSED_DIR / f"{raw_path.stem}_clean.json"

    if not raw_path.exists():
        log_ocr_warning(file_path, "‚ùå Tiedostoa ei l√∂ydy.")
        return []

    # K√§yt√§ v√§limuistia jos k√§sitelty aiemmin
    if output_file.exists():
        print(f"üìÇ K√§ytet√§√§n v√§limuistissa olevaa tiedostoa: {output_file}")
        with open(output_file, "r", encoding="utf-8") as f:
            data = json.load(f)
            text = data.get("text", "")
            return text_to_chunks(text)

    print(f"üß† Prosessoidaan dokumentti Unstructuredilla: {file_path}")
    text_output = extract_text_unstructured(file_path)

    # Jos ei l√∂ydetty teksti√§ ‚Üí kokeillaan OCR
    if not text_output.strip():
        log_ocr_warning(file_path, "‚ö†Ô∏è Ei tekstitasoa ‚Äì k√§ytet√§√§n OCR-varamenetelm√§√§.")
        text_output = run_paddleocr_fallback(file_path)

    if not text_output.strip():
        log_ocr_warning(file_path, "‚ùå OCR ep√§onnistui kokonaan.")
        return []

    # Tallenna k√§sitelty dokumentti
    PROCESSED_DIR.mkdir(parents=True, exist_ok=True)
    data = {"text": text_output}
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"üíæ Tallennettu k√§sitelty dokumentti: {output_file}")
    return text_to_chunks(text_output)


# ---------------------------------------------------------------------------
# ‚úÇÔ∏è Chunking-logiikka
# ---------------------------------------------------------------------------
def text_to_chunks(text: str, chunk_size: int = 400):
    """Jakaa tekstin loogisiksi kappaleiksi s√§ilytt√§en otsikkorakenteen."""
    paragraphs = text.split("\n\n")
    chunks, current_chunk = [], ""

    for para in paragraphs:
        if len(current_chunk) + len(para) < chunk_size:
            current_chunk += para + "\n\n"
        else:
            chunks.append(current_chunk.strip())
            current_chunk = para + "\n\n"

    if current_chunk.strip():
        chunks.append(current_chunk.strip())

    print(f"‚úÖ Prosessoidusta dokumentista saatiin {len(chunks)} tekstikappaletta.")
    return chunks
def preprocess_all_documents(originals_dir=None, processed_dir=None):
    """
    K√§sittelee kaikki alkuper√§iset dokumentit (PDF, DOCX, TXT) kansiosta `docs/originals`
    ja tallentaa ne JSON-muodossa kansioon `docs/processed`.

    Dokumentteja ei k√§sitell√§ uudelleen, jos vastaava *_clean.json on jo olemassa.
    """
    from pathlib import Path

    base_dir = Path(__file__).resolve().parents[2]
    originals_dir = Path(originals_dir or (base_dir / "docs/originals"))
    processed_dir = Path(processed_dir or (base_dir / "docs/processed"))

    originals_dir.mkdir(parents=True, exist_ok=True)
    processed_dir.mkdir(parents=True, exist_ok=True)

    files = [f for f in originals_dir.iterdir() if f.suffix.lower() in [".pdf", ".docx", ".txt"]]
    if not files:
        print(f"‚ö†Ô∏è Ei k√§sitelt√§vi√§ dokumentteja hakemistossa: {originals_dir}")
        return

    print(f"üìÑ K√§sitell√§√§n {len(files)} dokumenttia ennen indeksointia...\n")

    for f in files:
        processed_file = processed_dir / f"{f.stem}_clean.json"
        if processed_file.exists():
            print(f"‚úÖ V√§limuistissa: {f.name}")
            continue

        try:
            print(f"üß† Prosessoidaan dokumentti: {f.name}")
            text_chunks = process_with_unstructured(str(f))

            if text_chunks:
                text_output = " ".join(text_chunks)
                data = {"text": text_output}

                with open(processed_file, "w", encoding="utf-8") as outfile:
                    json.dump(data, outfile, ensure_ascii=False, indent=2)

                print(f"üíæ Tallennettu: {processed_file}")
            else:
                print(f"‚ö†Ô∏è Ei teksti√§ dokumentista: {f.name}")

        except Exception as e:
            log_ocr_warning(str(f), f"Virhe dokumentin k√§sittelyss√§: {e}")
            print(f"‚ùå Virhe k√§sitelt√§ess√§ {f.name}: {e}")

    print("\n‚úÖ Kaikki dokumentit k√§sitelty.")
